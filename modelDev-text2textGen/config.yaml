# NB: add '/' at the start of directories for ensured directory formatting

config_dir: /gpfs01/home/efykr2/MetroLLM/modelDev-text2textGen/config.yaml

#** Train **#
train:
  data:
    dir: "/gpfs01/home/efykr2/MetroLLM/data/3-formatted/t2tGen/t2tGen_train.csv"
    task_col: "task"
    input_col: "input"
    output_col: "output"
    max_seq_length: 256

  model:
    name: "google/flan-t5-small"
    max_input_length: 256
    max_target_length: 256

  training_args:
    output_dir:         "/gpfs01/home/efykr2/MetroLLM/modelDev-text2textGen/results/"
    eval_strategy:      "epoch"
    save_strategy:      "epoch"
    logging_strategy:   epoch
    logging_steps:      5
    learning_rate:      3e-4
    per_device_train_batch_size:    8
    per_device_eval_batch_size:     8
    gradient_accumulation_steps:    16
    weight_decay:               0.01
    warmup_ratio:               0.1
    num_train_epochs:           6
    predict_with_generate:      True
    generation_max_length:      128
    load_best_model_at_end:     True
    metric_for_best_model:      "rouge1"
    greater_is_better:          True
    bf16:                       True
    gradient_checkpointing:     True
    dataloader_pin_memory:      False
    label_smoothing_factor:     0.1
    save_total_limit:           3
    push_to_hub:                False

    log_training_steps:   True
    


#** Eval **#
eval:
  data:
    dir: "/data/3-formatted/t2tGen/t2tGen_test.csv"
    task_col: "task"
    input_col: "input"
    output_col: "output"
    max_seq_length: 256

  model:
    dir: "/modelDev-text2textGen/results/V2/checkpoint-1680/"
    max_input_length: 256
    max_target_length: 256

  eval_args:
    metric: "rouge"
    batch_size: 8
    output_dir: "/modelDev-text2textGen/results/V2/checkpoint-1680/eval_results.json"
